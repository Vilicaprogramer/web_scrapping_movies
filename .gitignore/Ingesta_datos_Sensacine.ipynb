{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "# üé¨ Explicaci√≥n Detallada del Script de Web Scraping de Sensacine (Para el Tutor) ü§ì\n",
    "\n",
    "> He preparado este script de web scraping con el objetivo de extraer informaci√≥n de pel√≠culas del sitio web Sensacine.  Soy consciente de que hay mucho por aprender, pero he intentado aplicar lo que he estudiado hasta ahora de la mejor manera posible.  A continuaci√≥n, encontrar√°s una explicaci√≥n detallada del c√≥digo.  ¬°Cualquier feedback o sugerencia ser√° muy valioso! üôè\n",
    "\n",
    "---\n",
    "\n",
    "**Puntos Clave para el Tutor:**\n",
    "\n",
    "*   **üï∏Ô∏è Web Scraping:** El c√≥digo demuestra el proceso de web scraping utilizando `requests` y `BeautifulSoup`, mostrando como hacer peticiones y como parsear la informaci√≥n de la web.\n",
    "\n",
    "*   **üõ°Ô∏è Manejo de Errores:** El uso de bloques `try-except` es crucial para la robustez del script, permitiendo que el proceso continue aunque algunas pel√≠culas no tengan todos los campos.\n",
    "\n",
    "*   **üîç Extracci√≥n de Datos:** El script muestra c√≥mo usar diferentes m√©todos de `BeautifulSoup` para encontrar y extraer datos espec√≠ficos bas√°ndose en el HTML de la p√°gina.\n",
    "\n",
    "*   **üóÑÔ∏è DataFrames:** La utilizaci√≥n de `pandas` DataFrame es muy √∫til para estructurar y organizar los datos extra√≠dos, para despu√©s almacenarlos en un archivo por ejemplo.\n",
    "\n",
    "*   **üîÑ Iteraci√≥n en P√°ginas Web:** El c√≥digo demuestra la l√≥gica para iterar a trav√©s de m√∫ltiples p√°ginas de una web para extraer informaci√≥n de varias p√°ginas.\n",
    "\n",
    "*   **‚öôÔ∏è Regex:** Muestra como usar expresiones regulares para buscar patrones en los datos\n",
    "\n",
    "*   **üö¶ Condicionales:** Muestra el uso de condicionales para extraer la informaci√≥n dependiendo de la cantidad de datos que tenga, como puede ser el caso de los g√©neros o los actores.\n",
    "\n",
    "*   **üîó B√∫squeda de Datos Relacionados:** Muestra c√≥mo hacer una b√∫squeda en una web secundaria con los datos extra√≠dos de la principal.\n",
    "\n",
    "En resumen, el c√≥digo proporciona una excelente base para el web scraping, demostrando una variedad de t√©cnicas y buenas pr√°cticas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5737,
     "status": "ok",
     "timestamp": 1729784605505,
     "user": {
      "displayName": "Vicen",
      "userId": "09487260677934822038"
     },
     "user_tz": -120
    },
    "id": "RGyX8lBIIOgS",
    "outputId": "4d97b1bc-2192-4224-bf35-6456804d477b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librer√≠as necesarias.\n",
    "\n",
    "import requests # Para hacer solicitudes HTTP\n",
    "from bs4 import BeautifulSoup # Para extraer informaci√≥n de las p√°ginas web\n",
    "import pandas as pd # Para trabajar con los datasets\n",
    "import re # Para trabajar con expresiones regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1sHei1Pg0SMAY1NN944gZhEgSdQAIb99Y"
    },
    "id": "5HKxH6HgVHJq",
    "outputId": "47f85148-9a36-4d36-b050-e756c0d4bf72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inicializamos un DataFrame vac√≠o para almacenar la informaci√≥n de las pel√≠culas.\n",
    "# Las columnas representan los datos que vamos a extraer de la p√°gina web.\n",
    "df_peliculas = pd.DataFrame(columns=['T√≠tulo', 'Fecha de Estreno', 'Duraci√≥n', 'G√©nero 1', 'G√©nero 2', 'G√©nero 3', 'Dirigida por', 'Actor 1', 'Actor 2', 'Actor 3', 'Medios Rate', 'Usuarios Rate', 'Sensacine Rate', 'Sinopsis', 'Sensacine Opini√≥n'])\n",
    "\n",
    "# Inicializamos la variable 'pg' para controlar el n√∫mero de p√°gina que vamos a procesar.\n",
    "pg = 1\n",
    "# Inicializamos 'last_page' para comparar la p√°gina actual con la anterior y detener el bucle si no hay cambios.\n",
    "last_page = None\n",
    "\n",
    "# Bucle infinito para recorrer todas las p√°ginas de pel√≠culas en la p√°gina web de Sensacine.\n",
    "while True:\n",
    "    # Realizamos la petici√≥n GET a la URL de la p√°gina actual.\n",
    "    html_doc = requests.get(f'https://www.sensacine.com/peliculas/todas-peliculas/?page={pg}')\n",
    "    # Creamos un objeto BeautifulSoup para parsear el HTML de la p√°gina.\n",
    "    soup1 = BeautifulSoup(html_doc.text, 'html.parser')\n",
    "    \n",
    "    # Comprobamos si la p√°gina actual es igual a la anterior (para detectar que hemos llegado a la √∫ltima p√°gina).\n",
    "    if soup1 == last_page:\n",
    "      print('Terminado')\n",
    "      break # Salimos del bucle si no hay cambios.\n",
    "    else:\n",
    "      # Si la p√°gina es diferente, actualizamos 'last_page' y continuamos.\n",
    "      last_page = soup1\n",
    "      # Buscamos todos los elementos 'li' con clase 'mdl', que corresponden a cada pel√≠cula en la p√°gina.\n",
    "      peliculas = soup1.find_all('li', class_='mdl')\n",
    "      # Inicializamos un diccionario para guardar los datos de cada pel√≠cula antes de pasarlos al DataFrame.\n",
    "      dc_peliculas = {}\n",
    "      print(f'Comenzando la p√°gina {pg}') # Indicamos la p√°gina que estamos procesando.\n",
    "      # Iteramos a trav√©s de cada pel√≠cula encontrada en la p√°gina.\n",
    "      for pelicula in peliculas:\n",
    "        # --- Extracci√≥n del t√≠tulo de la pel√≠cula ---\n",
    "        try:\n",
    "          # Intentamos extraer el t√≠tulo de la pel√≠cula.\n",
    "          title = pelicula.find('a', class_=\"meta-title-link\").get_text(strip=True)\n",
    "          dc_peliculas['T√≠tulo']= title # Guardamos el t√≠tulo en el diccionario.\n",
    "        except:\n",
    "          dc_peliculas['T√≠tulo']= None # Si no encontramos el t√≠tulo, guardamos None.\n",
    "        # --- Extracci√≥n de la fecha de estreno ---\n",
    "        try:\n",
    "          # Intentamos extraer la fecha de estreno.\n",
    "          dc_peliculas['Fecha de Estreno']= pelicula.find('div', class_='meta-body-item meta-body-info').find('span', class_=\"date\").get_text(strip=True)\n",
    "        except:\n",
    "          dc_peliculas['Fecha de Estreno']= None\n",
    "        # --- Extracci√≥n de la duraci√≥n ---\n",
    "        try:\n",
    "          # Intentamos extraer la duraci√≥n de la pel√≠cula.\n",
    "          dc_peliculas['Duraci√≥n']= pelicula.find('div', class_='meta-body-item meta-body-info').find(string= re.compile(\"[0-9]h\")).strip()\n",
    "        except:\n",
    "          dc_peliculas['Duraci√≥n']= None\n",
    "\n",
    "        # --- Extracci√≥n de los g√©neros ---\n",
    "        try:\n",
    "          # Intentamos extraer los g√©neros de la pel√≠cula.\n",
    "          generos = pelicula.find('div', class_='meta-body-item meta-body-info').find_all('span', class_=\"dark-grey-link\")\n",
    "          # Extraemos hasta 3 g√©neros si est√°n disponibles.\n",
    "          if len(generos) >= 1:\n",
    "            dc_peliculas['G√©nero 1'] = generos[0].get_text(strip=True)\n",
    "          else:\n",
    "            dc_peliculas['G√©nero 1'] = None\n",
    "          if len(generos) >= 2:\n",
    "            dc_peliculas['G√©nero 2'] = generos[1].get_text(strip=True)\n",
    "          else:\n",
    "            dc_peliculas['G√©nero 2'] = None\n",
    "          if len(generos) >= 3:\n",
    "            dc_peliculas['G√©nero 3'] = generos[2].get_text(strip=True)\n",
    "          else:\n",
    "            dc_peliculas['G√©nero 3'] = None\n",
    "        except:\n",
    "          dc_peliculas['G√©nero 1'], dc_peliculas['G√©nero 2'], dc_peliculas['G√©nero 3']= None # Si no encontramos g√©neros, guardamos None.\n",
    "\n",
    "        # --- Extracci√≥n del director ---\n",
    "        try:\n",
    "          # Intentamos extraer el nombre del director.\n",
    "          dc_peliculas['Dirigida por']= pelicula.find('div', class_='meta-body-item meta-body-direction').find('span', class_=\"dark-grey-link\").get_text(strip=True)\n",
    "        except:\n",
    "          dc_peliculas['Dirigida por']= None\n",
    "\n",
    "        # --- Extracci√≥n de los actores ---\n",
    "        try:\n",
    "          # Intentamos extraer los nombres de los actores.\n",
    "          actores = pelicula.find('div', class_='meta-body-item meta-body-actor').find_all('a', class_=\"dark-grey-link\")\n",
    "          # Inicializamos los actores a None\n",
    "          dc_peliculas['Actor 1'] = None\n",
    "          dc_peliculas['Actor 2'] = None\n",
    "          dc_peliculas['Actor 3'] = None\n",
    "          # Guardamos hasta 3 actores si est√°n disponibles.\n",
    "          if len(actores) == 1:\n",
    "            dc_peliculas['Actor 1'] = actores[0].get_text(strip=True)\n",
    "          elif len(actores) == 2:\n",
    "            dc_peliculas['Actor 1'] = actores[0].get_text(strip=True)\n",
    "            dc_peliculas['Actor 2'] = actores[1].get_text(strip=True)\n",
    "          else:\n",
    "            dc_peliculas['Actor 1'] = actores[0].get_text(strip=True)\n",
    "            dc_peliculas['Actor 2'] = actores[1].get_text(strip=True)\n",
    "            dc_peliculas['Actor 3'] = actores[2].get_text(strip=True)\n",
    "        except:\n",
    "          dc_peliculas['Actor 1'] = None\n",
    "          dc_peliculas['Actor 2'] = None\n",
    "          dc_peliculas['Actor 3'] = None\n",
    "\n",
    "        # --- Extracci√≥n del tercer actor (otra forma que se ve en la web) ---\n",
    "        try:\n",
    "          # Intentamos extraer el tercer actor en caso de que no estuviera en los links anteriores\n",
    "          dc_peliculas['Actor 3']= pelicula.find('div', class_='meta-body-item meta-body-actor').find('span', class_=\"dark-grey-link\").get_text(strip=True)\n",
    "        except:\n",
    "          dc_peliculas['Actor 3']= None\n",
    "\n",
    "        # --- Extracci√≥n de las valoraciones ---\n",
    "        try:\n",
    "          # Inicializamos las valoraciones a None\n",
    "          dc_peliculas['Medios Rate']= None\n",
    "          dc_peliculas['Usuarios Rate']= None\n",
    "          dc_peliculas['Sensacine Rate']= None\n",
    "          # Iteramos sobre los tipos de valoraci√≥n (Medios, Usuarios, Sensacine).\n",
    "          rate = 1\n",
    "          while rate <= 4:\n",
    "            try:\n",
    "                for i in pelicula.find('div', class_=f'rating-holder rating-holder-{rate}').find_all('span', class_='rating-title'):\n",
    "                  if i.get_text(strip=True) == 'Usuarios':\n",
    "                    dc_peliculas['Usuarios Rate'] = i.find_next('span', class_=\"stareval-note\").get_text(strip=True)\n",
    "                  elif i.get_text(strip=True) == 'Sensacine':\n",
    "                    dc_peliculas['Sensacine Rate']= i.find_next('span', class_=\"stareval-note\").get_text(strip=True)\n",
    "                  elif i.get_text(strip=True) == 'Medios':\n",
    "                    dc_peliculas['Medios Rate'] = i.find_next('span', class_=\"stareval-note\").get_text(strip=True)\n",
    "                  else:\n",
    "                    continue\n",
    "                rate += 1\n",
    "            except:\n",
    "              rate += 1\n",
    "        except:\n",
    "          dc_peliculas['Medios Rate']= None\n",
    "          dc_peliculas['Usuarios Rate']= None\n",
    "          dc_peliculas['Sensacine Rate']= None\n",
    "\n",
    "        # --- Extracci√≥n de la sinopsis ---\n",
    "        try:\n",
    "          # Intentamos extraer la sinopsis.\n",
    "          dc_peliculas['Sinopsis']= pelicula.find('div', class_='synopsis').find_next('div', class_=\"content-txt\").get_text().strip()\n",
    "        except:\n",
    "           dc_peliculas['Sinopsis']= None\n",
    "\n",
    "        # --- Extracci√≥n de la opini√≥n de Sensacine ---\n",
    "        try:\n",
    "          # Intentamos extraer la URL de la p√°gina de la pel√≠cula.\n",
    "          url = pelicula.find('a', class_=\"meta-title-link\").get('href')\n",
    "          # Realizamos la petici√≥n GET a la URL de la p√°gina de la pel√≠cula.\n",
    "          html_pelicula = requests.get(f'https://www.sensacine.com{url}sensacine/')\n",
    "          # Creamos un objeto BeautifulSoup para parsear el HTML de la p√°gina de la pel√≠cula.\n",
    "          soup2 = BeautifulSoup(html_pelicula.text, 'html.parser')\n",
    "          # Intentamos extraer la opini√≥n de Sensacine.\n",
    "          soup2.find('div', class_=\"editorial-content cf\").get_text().strip()\n",
    "          dc_peliculas['Sensacine Opini√≥n']= soup2.find('div', class_=\"editorial-content cf\").get_text().strip()\n",
    "        except:\n",
    "          dc_peliculas['Sensacine Opini√≥n']= None\n",
    "\n",
    "        # Agregamos la informaci√≥n de la pel√≠cula al DataFrame\n",
    "        df_peliculas.loc[len(df_peliculas)] = dc_peliculas\n",
    "        print(dc_peliculas) # Imprimimos el diccionario con los datos de la pel√≠cula que acabamos de extraer.\n",
    "      pg += 1 # Incrementamos el n√∫mero de p√°gina para la siguiente iteraci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nL_3AHG6MQVv"
   },
   "outputs": [],
   "source": [
    "df_peliculas.to_csv('pon_aqui_el_nombre_de_tu_archivo.csv', index=False)\n",
    "df_peliculas.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM57gN2bSyZmSPP+bz0niTI",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
